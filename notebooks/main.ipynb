{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from src.data_loader import LABEL_MAP\n",
    "from src.data_loader import load_datasets\n",
    "from src.model_pipeline import load_and_prep_datasets"
   ],
   "id": "b3a5d027d29635",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "55bc471f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Mini-Challenge\n",
    "\n",
    "> Authors: Dominik Filliger, Nils Fahrni, Noah Leuenberger (2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f4b2dd",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Sentiment analysis is a crucial task in Natural Language Processing (NLP) that involves determining the sentiment or tone of a given text. It has numerous applications, such as understanding customer feedback, monitoring social media sentiment, and analyzing product reviews. However, manually labeling large datasets for sentiment analysis can be time-consuming and costly. Semi-supervised learning techniques, such as weak supervision, can help alleviate this challenge by leveraging a small amount of labeled data along with a larger set of unlabeled data to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75667560",
   "metadata": {},
   "source": [
    " ## 2. Dataset Selection and Exploratory Data Analysis\n",
    "The dataset used for this mini-challenge is the Amazon Polarity dataset, which consists of product reviews from Amazon labeled as either positive or negative. The dataset is loaded using the Hugging Face Datasets library. Exploratory data analysis is performed to gain insights into the distribution of labels, length of reviews, and other relevant characteristics.\n",
    "\n",
    "As the dataset contains 4 million reviews we cut this down into a subset of 6666 reviews for the purpose of this mini-challenge. 666 of the reviews are used for validation, the remaining 6000 are split into 1000 labeled samples and 5000 artificially unlabeled samples.\n",
    "\n",
    "Each subset has a 50/50 split of positive and negative reviews. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_df, unlabeled, validation = load_datasets(\"../data/partitions\")\n",
    "\n",
    "print(f\"Labeled Dataset Length: {len(train_df)}\")\n",
    "print(f\"Unlabeled Dataset Length: {len(unlabeled)}\")\n",
    "print(f\"Validation Dataset Length: {len(validation)}\")"
   ],
   "id": "b7d121e24f626f5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To get a better idea of the whole dataset, we will merge the data again and perform some exploratory data analysis. For this purpose, we will merge the training, unlabeled, and validation datasets into one dataframe. We will also rename the 'ground_truth' column to 'label' in the unlabeled dataset to maintain consistency across the datasets.",
   "id": "e2a464f170d2351f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unlabeled.rename(columns={'ground_truth': 'label'}, inplace=True)  # Rename column for consistency\n",
    "eda_df = pd.concat([train_df, unlabeled, validation])\n",
    "eda_df['label'] = eda_df['label'].map(LABEL_MAP)  # Map labels to 0: Negative, 1: Positive\n",
    "\n",
    "print(f\"Merged Dataset Length: {len(eda_df)}\")\n",
    "eda_df.head()"
   ],
   "id": "bd69ceb3469b9745",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eda_df['review_length'] = eda_df['content'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(eda_df['review_length'], bins=50, kde=True)\n",
    "plt.title('Distribution of Review Lengths in Training Data')\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "id": "5b0b9ca062123f99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The distribution of review lengths in the dataset is visualized using a histogram. The majority of reviews have a length between 0 and 1000 characters, with a peak around 500 characters. This information can be useful for preprocessing and feature engineering steps in the sentiment analysis task.",
   "id": "8cb051063ad5b7f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Most Common Words",
   "id": "5a1f960b012c2b6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_most_common_words(df, top_n=20):\n",
    "    df = df.copy()\n",
    "    df['label'] = df['label'].map({v: k for k, v in LABEL_MAP.items()})\n",
    "    pos_reviews = df[df['label'] == 1]['content']\n",
    "    neg_reviews = df[df['label'] == 0]['content']\n",
    "\n",
    "    vectorizer_pos = CountVectorizer(stop_words='english')\n",
    "    vectorizer_neg = CountVectorizer(stop_words='english')\n",
    "\n",
    "    pos_word_count = vectorizer_pos.fit_transform(pos_reviews)\n",
    "    neg_word_count = vectorizer_neg.fit_transform(neg_reviews)\n",
    "\n",
    "    pos_sum_words = pos_word_count.sum(axis=0)\n",
    "    neg_sum_words = neg_word_count.sum(axis=0)\n",
    "\n",
    "    pos_words_freq = [(word, pos_sum_words[0, idx]) for word, idx in\n",
    "                      zip(vectorizer_pos.get_feature_names_out(), range(pos_sum_words.shape[1]))]\n",
    "    neg_words_freq = [(word, neg_sum_words[0, idx]) for word, idx in\n",
    "                      zip(vectorizer_neg.get_feature_names_out(), range(neg_sum_words.shape[1]))]\n",
    "\n",
    "    pos_words_freq = sorted(pos_words_freq, key=lambda x: x[1], reverse=True)\n",
    "    neg_words_freq = sorted(neg_words_freq, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    words, freq = zip(*pos_words_freq[:top_n])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(words, freq)\n",
    "    plt.title('Most common words in positive reviews')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "    words, freq = zip(*neg_words_freq[:top_n])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(words, freq)\n",
    "    plt.title('Most common words in negative reviews')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_most_common_words(eda_df, top_n=20)"
   ],
   "id": "8b944f080f06f4b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The most common words in positive and negative reviews are visualized using bar plots. The top 20 most frequent words in each category are displayed, providing insights into the language used in positive and negative reviews.",
   "id": "2f82857c221e4833"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Word Clouds",
   "id": "c818f28f4e8bde81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_word_cloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=800,\n",
    "                          background_color='white',\n",
    "                          stopwords=set(STOPWORDS),\n",
    "                          min_font_size=10).generate(text)\n",
    "\n",
    "    plt.figure(figsize=(8, 8), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ],
   "id": "eda21d9741f19da5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pos_reviews_text = \" \".join(eda_df[eda_df['label'] == \"positive\"]['content'].values)\n",
    "generate_word_cloud(pos_reviews_text, \"Word Cloud for Positive Reviews\")"
   ],
   "id": "b6ab0019c556ed8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "neg_reviews_text = \" \".join(eda_df[eda_df['label'] == \"negative\"]['content'].values)\n",
    "generate_word_cloud(neg_reviews_text, \"Word Cloud for Negative Reviews\")"
   ],
   "id": "3aeefd9b49d6905",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6b901248",
   "metadata": {},
   "source": [
    "## 3. Data Splitting Strategy\n",
    "The dataset is split into development, validation, labeled, and unlabeled sets using a nested split approach. The development set is a fraction of the full dataset, the validation set is a fraction of the test dataset, and the labeled set is a fraction of the development set. The remaining samples in the development set are considered unlabeled. The nested split always adds in 25% increments (25, 50, 75), and a 1/6 split between labelled and unlabelled data is used, resulting in 1000 labeled and 5000 weakly labeled samples in total.\n",
    "\n",
    "All the pre-split datasets are stored in the `data/partitions` directory as `.parquet` files.\n",
    "\n",
    "Given the focus of the MC on the impact of weak labelling and its impact, we introduce a nested split which further divides our training data into splits. Here is a brief overview of the nested split algorithm we use:\n",
    "\n",
    "1. **Validate the Fractions**: We start by ensuring that the proportions we want to use for our subsets are reasonableâ€”each should be a fraction of the whole dataset.\n",
    "2. **Shuffle the Data**: To make sure our subsets are representative and unbiased, we randomly shuffle the entire dataset. This ensures that each subset is a good mix of the data.\n",
    "3. **Forming the Subsets**: For each proportion we decided on, we calculate how much of the dataset it represents. Starting with the smallest subset, we keep adding more data until we reach the desired size for each proportion. Each new subset contains all the data from the previous subsets, plus some more.\n",
    "4. **Collect the Subsets**: In the end, we have a series of nested subsets, each larger than the last.\n",
    "\n",
    "The implementation of the nested split is used in the `load_and_prep_datasets` function in the `src/model_pipeline.py` module and separately implemented in the `src/prep_datasets.py` script.\n",
    "\n",
    "As the goal is to identify the optimal amount of additional data that can be used to improve model performance without the need for manual annotation. For this purpose: When training with weak labels we only apply the nested split on the weak labels and not the labeled data and then concat every given nested split with all the labeled data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5), sharey=True)\n",
    "\n",
    "\n",
    "def add_percentages(ax, data):\n",
    "    total = len(data)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        percentage = f'{(height / total) * 100:.1f}%'\n",
    "        ax.text(p.get_x() + p.get_width() / 2., height, percentage, ha='center', va='bottom')\n",
    "\n",
    "\n",
    "sns.countplot(data=train_df, x='label', ax=ax[0])\n",
    "add_percentages(ax[0], train_df)\n",
    "ax[0].set_title('Labeled Dataset')\n",
    "ax[0].set_xlabel('Label')\n",
    "ax[0].set_ylabel('Count')\n",
    "\n",
    "sns.countplot(data=unlabeled, x='label', ax=ax[1])\n",
    "add_percentages(ax[1], unlabeled)\n",
    "ax[1].set_title('Unlabeled Dataset')\n",
    "ax[1].set_xlabel('Ground Truth')\n",
    "\n",
    "sns.countplot(data=validation, x='label', ax=ax[2])\n",
    "add_percentages(ax[2], validation)\n",
    "ax[2].set_title('Validation Dataset')\n",
    "ax[2].set_xlabel('Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "73e761cf1be82629",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The distribution of labels in the labeled, unlabeled, and validation datasets is visualized using count plots. The percentage of positive and negative reviews in each dataset is displayed, providing insights into the class distribution of the data. As we can see, the datasets are balanced with a 50/50 split between positive and negative reviews making imbalanced classes no issue for our models.",
   "id": "1208a1b815c2df7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "preped_datasets = load_and_prep_datasets(\"../data\", nested_splits=True)\n",
    "logging.disable(\n",
    "    logging.CRITICAL)  # Disable logging for this cell as logging is initialized in the load_and_prep_datasets function\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "sns.barplot(x=list(preped_datasets['nested_splits'].keys()),\n",
    "            y=[len(value) for value in preped_datasets['nested_splits'].values()], ax=ax)\n",
    "ax.set_title('Nested Split Sizes')\n",
    "ax.set_xlabel('Nested Split Fraction')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "total = len(preped_datasets['train'])\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    percentage = f'{(height / total) * 100:.1f}%'\n",
    "    ax.text(p.get_x() + p.get_width() / 2., height, percentage, ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ],
   "id": "d2e07a60e048ddfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The sizes of the nested splits generated from the training data are visualized using a bar plot. The count of samples in each nested split is displayed, along with the percentage of the total training data that each split represents. The nested splits are created in 25% increments, starting from 25% of the training data and increasing to 100% of the training data. In this visualization the nested split was only applied to the labeled data but the picture would be the same if it was applied to the weak labels.",
   "id": "91b113205d7242d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(10, 5), sharey=True)\n",
    "\n",
    "for i, (key, value) in enumerate(preped_datasets['nested_splits'].items()):\n",
    "    value = value.to_pandas()\n",
    "    sns.countplot(data=value, x='label', ax=ax[i])\n",
    "    add_percentages(ax[i], value)\n",
    "    ax[i].set_title(f'Nested Split {key}')\n",
    "    ax[i].set_xlabel('Label')\n",
    "    ax[i].set_ylabel('Count')"
   ],
   "id": "88e3250115fcb9a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The distribution of labels in each nested split is visualized using count plots. The percentage of positive and negative reviews in each nested split is displayed, providing insights into the class distribution of the data. The nested splits maintain a balanced distribution of positive and negative reviews, as the set the data is sampled from is also balanced.",
   "id": "2388c008fca6b305"
  },
  {
   "cell_type": "markdown",
   "id": "47939c9e",
   "metadata": {},
   "source": [
    "## 4. Baseline Model Performance\n",
    "A pretrained language model, specifically `sentence-transformers/all-MiniLM-L6-v2`, is used as the baseline model for sentiment classification without training. The baseline model's performance is evaluated and the implications of the results are discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef2289",
   "metadata": {},
   "source": [
    "## 5. Supervised Learning Performance\n",
    "Supervised learning techniques, including transfer learning and fine-tuning, are applied to the sentiment classification task using different amounts of labeled samples. The impact of the number of labeled samples on model performance is analyzed and presented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317a134",
   "metadata": {},
   "source": [
    "### 5.1 Transfer Learning\n",
    "The performance of transfer learning using different amounts of labeled samples is presented and discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d7a8e1",
   "metadata": {},
   "source": [
    "### 5.2 Fine-tuning\n",
    "The performance of fine-tuning using different amounts of labeled samples is presented and discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cfcf6e",
   "metadata": {},
   "source": [
    "## 6. Semi-Supervised Learning Performance\n",
    "Semi-supervised learning techniques, specifically K-Nearest Neighbors (KNN) and Logistic Regression (LogReg), are employed to generate weak labels for the unlabeled samples. The impact of the number of labeled samples and weak labeling strategies on model performance is analyzed and presented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c55c17",
   "metadata": {},
   "source": [
    "### 6.1 K-Nearest Neighbors (KNN)\n",
    "The performance of KNN-based weak labeling using different amounts of labeled samples is presented and discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c53e734",
   "metadata": {},
   "source": [
    "### 6.2 Logistic Regression (LogReg)\n",
    "The performance of LogReg-based weak labeling using different amounts of labeled samples is presented and discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d33785",
   "metadata": {},
   "source": [
    "## 7. Learning Curve Analysis\n",
    "The learning curve, plotting the model performance against varying numbers of labeled samples for each technique (supervised and semi-supervised), is presented and analyzed. The focus is on the range with few labeled samples, and the practical implications of the results are discussed."
   ]
  },
  {
   "cell_type": "code",
   "id": "eabcf731",
   "metadata": {},
   "source": [
    "# Code for generating the learning curve plot"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7ce2752d",
   "metadata": {},
   "source": [
    "## 8. Model Comparison and Analysis\n",
    "A thorough analysis of the results is conducted, comparing the baseline model, supervised learning techniques, and semi-supervised learning techniques. The impact of different weak labeling strategies and training data sizes on model performance is evaluated. The best approach for the chosen dataset is determined, emphasizing the models that achieve acceptable performance with few manually annotated samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45316041",
   "metadata": {},
   "source": [
    "## 9. Time Savings Factor and Implications\n",
    "The time savings factor, quantifying the reduction in manually labeled data required to achieve acceptable performance levels using weak labeling approaches, is calculated. The implications of the findings are discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd172b",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Future Directions\n",
    "The key findings, insights, and potential implications of the sentiment analysis mini-challenge are summarized. The effectiveness of weak supervision techniques in reducing the need for manual annotation while maintaining acceptable model performance is discussed. Future directions for research and improvements are outlined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595d590",
   "metadata": {},
   "source": [
    "## 11. AI Tool Usage Assessment\n",
    "The use of ChatGPT or other AI tools throughout the mini-challenge is documented and assessed. The tasks for which they were used, the prompting strategies employed, and their contribution to solving the problem and acquiring new skills are specified."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
