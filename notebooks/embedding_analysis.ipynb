{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook at hand aims to dive into the possible patterns dimensionality reduction techniques can show within the proposed weak labeling models and the embedding models used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Weak Labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "plotly.offline.init_notebook_mode()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getenv('DATA_DIR', 'data')\n",
    "EMBEDDING_DATA_DIR = os.path.abspath(os.path.join(parent_dir, DATA_DIR, 'embeddings'))\n",
    "\n",
    "weak_labelled = {}\n",
    "\n",
    "print(f\"Reading weak labelled data from {EMBEDDING_DATA_DIR}\")\n",
    "\n",
    "embedding_model_dirs = [d for d in os.listdir(EMBEDDING_DATA_DIR) if os.path.isdir(os.path.join(EMBEDDING_DATA_DIR, d))]\n",
    "embeddings = {}\n",
    "\n",
    "for dir in embedding_model_dirs:\n",
    "    print(f\"- Opening Embeddings from {dir}\")\n",
    "    curr_embeddings = {}\n",
    "    for file in os.listdir(os.path.join(EMBEDDING_DATA_DIR, dir)):\n",
    "        if file.endswith('.pkl'):\n",
    "            filename = file.split('.')[0]\n",
    "            curr_embeddings[filename] = pd.read_pickle(os.path.join(EMBEDDING_DATA_DIR, dir, file))\n",
    "        print(f\"  - Read {file}\")\n",
    "    embeddings[dir] = curr_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTITIONS_DATA_DIR = os.path.abspath(os.path.join(parent_dir, DATA_DIR, 'partitions'))\n",
    "\n",
    "print(f\"Reading partitions data from {PARTITIONS_DATA_DIR}\")    \n",
    "\n",
    "partitions = {}\n",
    "\n",
    "for file in os.listdir(PARTITIONS_DATA_DIR):\n",
    "    if file.endswith('.parquet'):\n",
    "        filename = file.split('.')[0]\n",
    "        partitions[filename] = pd.read_parquet(os.path.join(PARTITIONS_DATA_DIR, file))\n",
    "    print(f'- Read {file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging content, title and label to embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_partitions = {}\n",
    "\n",
    "for embedding_model in embeddings:\n",
    "    merged_partitions[embedding_model] = {}\n",
    "    print(f'For {embedding_model}:')\n",
    "    for partition in partitions:\n",
    "        curr_partition_name = partition.split('_')[0]\n",
    "        embeddings_keys = embeddings[embedding_model].keys()\n",
    "        \n",
    "        for embedding_key in embeddings_keys:\n",
    "            if curr_partition_name == embedding_key.split('_')[0]:\n",
    "                partition_data = partitions[partition]\n",
    "                embedding_data = embeddings[embedding_model][embedding_key]\n",
    "                partition_data['embedding'] = embedding_data.tolist()\n",
    "                \n",
    "                merged_partitions[embedding_model][partition] = partition_data\n",
    "                \n",
    "                print(f\"- Merged {embedding_key} with {partition}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all partitions for each embedding model\n",
    "for embedding_model in merged_partitions:\n",
    "    print(f\"Concatenating partitions for {embedding_model}\")\n",
    "    partitions_data = pd.concat(merged_partitions[embedding_model].values(), ignore_index=True)\n",
    "    merged_partitions[embedding_model] = partitions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_partitions['mini_lm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Labeled data\n",
    "To project the high dimensional embeddings into a humanly readable format we implemented Arize's Phoenix app that allows us to interactively look at the embedding space projected down into 3 dimensions by UMAP.\n",
    "\n",
    "Additionally, it might be insightful to also look at a different dimension reduction approach - Therefore we made the `plot_pca` function which will project the embedding space into two dimensions using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def break_content(text, length=50):\n",
    "    lines = []\n",
    "    while len(text) > length:\n",
    "        space_index = text.rfind(' ', 0, length)\n",
    "        if space_index == -1:\n",
    "            space_index = length\n",
    "        lines.append(text[:space_index])\n",
    "        text = text[space_index:].lstrip()\n",
    "    lines.append(text)\n",
    "    return '<br>'.join(lines)\n",
    "\n",
    "\n",
    "def plot_pca(weak_labelled, key):\n",
    "    if key not in weak_labelled:\n",
    "        raise ValueError(f\"File {key} not found in the weak_labelled dictionary.\")\n",
    "\n",
    "    df = weak_labelled[key]\n",
    "\n",
    "    embeddings = np.vstack(df['embedding'].values)\n",
    "    content = df['content'].apply(lambda x: break_content(x)).values\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    pca_df = pd.DataFrame(reduced_embeddings, columns=['PCA1', 'PCA2', 'PCA3'])\n",
    "    pca_df['Content'] = content\n",
    "\n",
    "    fig = px.scatter_3d(pca_df, x='PCA1', y='PCA2', z='PCA3',\n",
    "                        title=f'PCA of Embedding Vectors for {key}',\n",
    "                        size_max=5, opacity=0.6, height=800,\n",
    "                        hover_data={'Content': True})\n",
    "    fig.update_traces(marker=dict(size=2))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniLM Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.px_utils import create_dataset, launch_px\n",
    "\n",
    "knn_key = 'mlp_weak_labeling_weaklabels.parquet'\n",
    "\n",
    "mini_lm_ds = create_dataset('mini_lm', merged_partitions['mini_lm'], merged_partitions['mini_lm']['embedding'], content=merged_partitions['mini_lm']['content'])\n",
    "\n",
    "px_session = launch_px(mini_lm_ds, None)\n",
    "px_session.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding positions in the space are relatively clearly clustered. In this first example we are using the embedding vectors of huggingface's `all-MiniLM-L6-v2` BERT sentence transformer. This sentence transformer was trained on sentence pairs that appear as a Q&A. The resulting vector embedding therefore describes the semantic content of such a sentence - This is exactly what we can see in the embedding space; Reviews of the `amazon-polarity` dataset are clustered together according to their product niche, as for example already mentioned with the cluster containing music reviews.\n",
    "\n",
    "But we can also observe other semantic relationships:\n",
    "- Video game reviews lie between music and book reviews: This axis could perhaps describe interactivity; music can be enjoyed passively, games do have some interactions between cutscenes while books capture ones concentration and attention entirely.\n",
    "- Video game reviews lie opposite of tech gadgets and other devices: This axis might describe the abstraction of virtuality. Games are completely virtual tech while tech gadgets are physical devices.\n",
    "- Kid's toys are clustered between games and tech gadgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Phoenix doesn't allow for a different dimension reduction technique we implement a PCA strategy ourselves. The UMAP technique differs vastly from PCA so looking at another technique could yield more interesting observations in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca(merged_partitions, 'mini_lm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the UMAP representation the PCA reduction doesn't seem to show much more separation in labels or semantics. We can still roughly see the following four clusters:\n",
    "- Music albums\n",
    "- Books\n",
    "- Movies\n",
    "- Tech Gadgets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
