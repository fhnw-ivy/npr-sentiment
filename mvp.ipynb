{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# npr MC2: Sentiment Analysis"
   ],
   "id": "8debd106f5c41475"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "DEV_SET_FRAC = 0.001\n",
    "OVERWRITE_SETS_WITH_DEV = True\n",
    "os.environ[\"WANDB_ENTITY\"] = \"lang-based-yappers\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"amazon_sentiment_analysis\"\n",
    "SEED = 1337"
   ],
   "id": "7a343cc59a37afdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "def set_seed():\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()"
   ],
   "id": "ae172404e4ebc86c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Loading the Dataset"
   ],
   "id": "5d0d4687ac7367ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"amazon_polarity\")\n",
    "dataset"
   ],
   "id": "6ff83614223e9f06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_ds, test_ds = dataset['train'], dataset['test']\n",
    "train_df, test_df = train_ds.to_pandas(), test_ds.to_pandas()"
   ],
   "id": "35b34a1a6a17c5ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get unique labels\n",
    "train_df['label'].unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8330e1c872c0d593",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f2c95fc0bb94843",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df.info()"
   ],
   "id": "8db070b89c95c5d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_df_dev = train_df.sample(frac=DEV_SET_FRAC, random_state=1337)\n",
    "test_df_dev = test_df.sample(frac=DEV_SET_FRAC, random_state=1337)\n",
    "\n",
    "if OVERWRITE_SETS_WITH_DEV:\n",
    "    train_df = train_df_dev\n",
    "    test_df = test_df_dev\n",
    "    \n",
    "    train_ds = train_ds.select(range(len(train_df)))\n",
    "    test_ds = test_ds.select(range(len(test_df)))\n",
    "\n",
    "print(f\"Training data shape: {train_df_dev.shape}, Testing data shape: {test_df_dev.shape}\")"
   ],
   "id": "81a1a84cfffc98e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis"
   ],
   "id": "35d1c2de1afc78f1"
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='label', data=train_df)\n",
    "plt.title('Label Distribution in Training Data')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bc407c4354a5129",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df['review_length'] = train_df['content'].apply(len)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['review_length'], bins=50, kde=True)\n",
    "plt.title('Distribution of Review Lengths in Training Data')\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c202341d0fdd53",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def plot_most_common_words(df, top_n=20):\n",
    "    pos_reviews = df[df['label'] == 1]['content']\n",
    "    neg_reviews = df[df['label'] == 0]['content']\n",
    "\n",
    "    vectorizer_pos = CountVectorizer(stop_words='english')\n",
    "    vectorizer_neg = CountVectorizer(stop_words='english')\n",
    "\n",
    "    pos_word_count = vectorizer_pos.fit_transform(pos_reviews)\n",
    "    neg_word_count = vectorizer_neg.fit_transform(neg_reviews)\n",
    "\n",
    "    pos_sum_words = pos_word_count.sum(axis=0)\n",
    "    neg_sum_words = neg_word_count.sum(axis=0)\n",
    "\n",
    "    pos_words_freq = [(word, pos_sum_words[0, idx]) for word, idx in\n",
    "                      zip(vectorizer_pos.get_feature_names_out(), range(pos_sum_words.shape[1]))]\n",
    "    neg_words_freq = [(word, neg_sum_words[0, idx]) for word, idx in\n",
    "                      zip(vectorizer_neg.get_feature_names_out(), range(neg_sum_words.shape[1]))]\n",
    "\n",
    "    pos_words_freq = sorted(pos_words_freq, key=lambda x: x[1], reverse=True)\n",
    "    neg_words_freq = sorted(neg_words_freq, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    words, freq = zip(*pos_words_freq[:top_n])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(words, freq)\n",
    "    plt.title('Most common words in positive reviews')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "    words, freq = zip(*neg_words_freq[:top_n])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(words, freq)\n",
    "    plt.title('Most common words in negative reviews')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    \n",
    "plot_most_common_words(train_df_dev)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16e5ab3e96884fed",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "def generate_word_cloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=800,\n",
    "                          background_color='white',\n",
    "                          stopwords=set(STOPWORDS),\n",
    "                          min_font_size=10).generate(text)\n",
    "\n",
    "    plt.figure(figsize=(8, 8), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "pos_reviews_text = \" \".join(review for review in train_df_dev[train_df_dev['label'] == 1]['content'])\n",
    "generate_word_cloud(pos_reviews_text, \"Word Cloud for Positive Reviews\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737b0525d667d911",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "neg_reviews_text = \" \".join(review for review in train_df_dev[train_df_dev['label'] == 0]['content'])\n",
    "generate_word_cloud(neg_reviews_text, \"Word Cloud for Negative Reviews\")"
   ],
   "id": "64a30c7bab35408c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine-tuning\n",
    "\n",
    "## Pretrained Model"
   ],
   "id": "d94be54705673da4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, force_download=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, force_download=True) # TODO: current model only supports 2 labels (positive, negative) but we have 3 labels (positive, neutral, negative)"
   ],
   "id": "6f60c9046bf3b2d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# print count model parameters\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(f\"Model has {params} trainable parameters.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "956f58188031f124",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "92b05a2823b5dafe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creation of Stratified Subsets"
   ],
   "id": "c801fe4965e97bc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def create_cumulative_stratified_subsets(df, percentages, label_column, as_datasets=True):\n",
    "    \"\"\"\n",
    "    Creates cumulative, stratified subsets of a dataset based on increasing percentages,\n",
    "    ensuring each subset is a superset of the previous ones.\n",
    "\n",
    "    :param df: pandas DataFrame to be split.\n",
    "    :param percentages: Increasing list of percentages for subset sizes.\n",
    "    :param label_column: Name of the column for stratification.\n",
    "    :return: Dictionary with percentages as keys and subset DataFrames as values.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"The input must be a pandas DataFrame.\")\n",
    "    \n",
    "    if percentages[-1] != 100:\n",
    "        raise ValueError(\"The last percentage must be 100 to ensure full dataset coverage.\")\n",
    "\n",
    "    subsets = {}\n",
    "    cumulative_subset_indices = set()\n",
    "\n",
    "    for percentage in percentages:\n",
    "        target_subset_size = int(len(df) * (percentage / 100))\n",
    "        additional_rows_needed = target_subset_size - len(cumulative_subset_indices)\n",
    "        \n",
    "        if additional_rows_needed <= 0:\n",
    "            continue  # Skip if no new rows need to be added (defensive, should not happen)\n",
    "\n",
    "        remaining_data = df.loc[~df.index.isin(cumulative_subset_indices)]\n",
    "        if additional_rows_needed >= len(remaining_data):\n",
    "            new_subset = remaining_data\n",
    "        else:\n",
    "            _, new_subset = train_test_split(\n",
    "                remaining_data, \n",
    "                test_size=additional_rows_needed / len(remaining_data), \n",
    "                stratify=remaining_data[label_column],\n",
    "                random_state=SEED\n",
    "            )\n",
    "\n",
    "        cumulative_subset_indices.update(new_subset.index)\n",
    "        subsets[percentage] = df.loc[sorted(cumulative_subset_indices)]\n",
    "\n",
    "    if as_datasets:\n",
    "        for percentage, subset in subsets.items():\n",
    "            subsets[percentage] = Dataset.from_pandas(subset)\n",
    "\n",
    "    return subsets\n",
    "\n",
    "train_ds_subsets = create_cumulative_stratified_subsets(train_df, [i for i in range(10, 101, 10)], 'label', as_datasets=True)\n",
    "for percentage, subset in train_ds_subsets.items():\n",
    "    print(f\"Subset size for {percentage}%: {len(subset)}, type: {type(subset)}\")"
   ],
   "id": "2e8b0a53cda37a64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "id": "72bafa2b410e1c6"
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_epochs = 3\n",
    "training_batch_size = 16\n",
    "logging_steps = len(train_df) // training_batch_size\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Use hyperparams for fine-tuning stated on https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
    "training_args = TrainingArguments(output_dir=MODEL_NAME,\n",
    "                                  num_train_epochs=training_epochs,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=training_batch_size,\n",
    "                                  per_device_eval_batch_size=training_batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  log_level=\"error\",\n",
    "                                  report_to=\"wandb\",\n",
    "                                  run_name=\"amazon_sentiment_analysis\",\n",
    "                                  optim=\"adamw_torch\"\n",
    "                                  )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bb1e24d3ad77bb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize(batch, max_length=512):\n",
    "    return tokenizer(batch['content'], padding=True, truncation=True, max_length=max_length)\n",
    "\n",
    "def tokenize_dataset(dataset, max_size=100, process_batch_size=100, batched=True):\n",
    "    \"\"\" Tokenizes the dataset \"\"\"\n",
    "    if not isinstance(dataset, Dataset):\n",
    "        raise ValueError(\"The dataset must be a huggingface Dataset object.\")\n",
    "    return dataset.map(lambda batch: tokenize(batch, max_size), batched=batched, batch_size=process_batch_size)\n",
    "\n",
    "train_ds_tokenized = tokenize_dataset(train_ds)\n",
    "test_ds_tokenized = tokenize_dataset(test_ds)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6d53bab06d15ad5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Metrics"
   ],
   "id": "afa7923a0b44e1f5"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels, preds = pred.label_ids, pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "793a9a859d036d14",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainerCallback\n",
    "\n",
    "class EpochResultsCallback(TrainerCallback):\n",
    "    \"\"\"A custom callback to capture and log results at the end of each epoch.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.results_df = pd.DataFrame(columns=['Epoch', 'Validation Loss', 'Accuracy', 'F1'])\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        new_row = {\n",
    "            'Epoch': state.epoch,\n",
    "            'Validation Loss': metrics['eval_loss'],\n",
    "            'Accuracy': metrics.get('eval_accuracy', None),\n",
    "            'F1': metrics.get('eval_f1', None)\n",
    "        }\n",
    "        self.results_df = pd.concat([self.results_df, pd.DataFrame(new_row, index=[0])])\n",
    "\n",
    "\n",
    "def fine_tune_model(model, training_args, train_dataset, eval_dataset, tokenizer):\n",
    "    epoch_results_callback = EpochResultsCallback()\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        callbacks=[epoch_results_callback]\n",
    "    )\n",
    "    \n",
    "    trainer.evaluate()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.train()\n",
    "\n",
    "    return epoch_results_callback.results_df\n",
    "\n",
    "eval_df = fine_tune_model(model, training_args, train_ds_tokenized, test_ds_tokenized, tokenizer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5155e78be1c3b9ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eval_df"
   ],
   "id": "964f1e7bfda45b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# ## TODO WIP is broke but ideally I want to extract the embeddings and predictions from the model and add them to the dataset so we can look at them in phoenix\n",
    "# def postprocess(batch):\n",
    "#     inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "#     with torch.no_grad():\n",
    "#         out = model(**inputs)                         # Extract prediction labels\n",
    "#         pred_label = out.logits.argmax(dim=1)           # Extract embedding vectors\n",
    "#         hidden_states = torch.stack(out.hidden_states)  # (layer_#, batch_size, seq_length/or/num_tokens, hidden_size)\n",
    "#         embeddings = hidden_states[-1][:,0,:]           # Select last layer, then CLS token vector\n",
    "#     return {\"text_vector\": embeddings.cpu().numpy(), \"pred_label\": pred_label.cpu().numpy()}\n",
    "# \n",
    "# batch_size = 100\n",
    "# \n",
    "# \n",
    "# train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "# train_ds = train_ds.map(postprocess, batched=True, batch_size=batch_size)\n",
    "# \n",
    "# test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "# test_ds = test_ds.map(postprocess, batched=True, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad5a2470c44652b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def postprocess(batch, model, tokenizer, device):\n",
    "#     inputs = {k: v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
    "#     \n",
    "#     with torch.no_grad():\n",
    "#         out = model(**inputs)\n",
    "#         pred_label = out.logits.argmax(dim=1)\n",
    "#         hidden_states = torch.stack(out.hidden_states)\n",
    "#         embeddings = hidden_states[-1][:, 0, :]\n",
    "#     \n",
    "#     return {\"text_vector\": embeddings.cpu().numpy(), \"pred_label\": pred_label.cpu().numpy()}\n",
    "# \n",
    "# def apply_postprocess_to_dataset(dataset, model, tokenizer, device, batch_size):\n",
    "#     dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "#     return dataset.map(lambda batch: postprocess(batch, model, tokenizer, device),\n",
    "#                        batched=True, batch_size=batch_size)\n",
    "# \n",
    "# batch_size = 100\n",
    "# train_ds = apply_postprocess_to_dataset(train_ds, model, tokenizer, device, batch_size)\n",
    "# test_ds = apply_postprocess_to_dataset(test_ds, model, tokenizer, device, batch_size)"
   ],
   "id": "b4ac27d4b3098dde",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
