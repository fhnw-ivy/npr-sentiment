{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"amazon_polarity\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from arize.pandas.embeddings import EmbeddingGenerator, UseCases\n",
    "model_name = 'distilbert/distilbert-base-uncased-finetuned-sst-2-english'\n",
    "generator = EmbeddingGenerator.from_use_case(\n",
    "    use_case=UseCases.NLP.SEQUENCE_CLASSIFICATION,\n",
    "    model_name=model_name,\n",
    ")\n",
    "\n",
    "num_labels = dataset['train'].features['label'].num_classes\n",
    "print(f\"Number of labels: {num_labels}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3596ca10c202b2c0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# todo current model only supports 3 labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b02d6dd44222f5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8dcdbf24adc2a429",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the sizes of the datasets you want to create\n",
    "dataset_sizes = [100, 500, 1000, 5000, 10000, 50000]\n",
    "\n",
    "nested_datasets = {}\n",
    "previous_end_index = 0\n",
    "\n",
    "for size in dataset_sizes:\n",
    "    # Calculate the end index for the current subset\n",
    "    end_index = previous_end_index + size\n",
    "    # Ensure that we do not exceed the total number of rows in the dataset\n",
    "    if end_index > len(dataset[\"train\"]):\n",
    "        print(f\"Requested size for {size} exceeds available data. Adjusting to maximum available.\")\n",
    "        end_index = len(dataset[\"train\"])\n",
    "\n",
    "    # Select the subset from the dataset\n",
    "    subset = dataset[\"train\"].select(range(previous_end_index, end_index))\n",
    "    nested_datasets[size] = subset\n",
    "\n",
    "    # Update the previous end index for the next iteration\n",
    "    previous_end_index = end_index\n",
    "\n",
    "train_ds = nested_datasets[1000]\n",
    "test_ds = dataset[\"test\"].select(range(100))\n",
    "\n",
    "train_df = train_ds.data.to_pandas()\n",
    "test_df = test_ds.data.to_pandas()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a798bfc78adc2082",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "477f546855f2a832",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Summary statistics for the training dataset\n",
    "print(\"Training Dataset Summary Statistics:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "# Summary statistics for the test dataset\n",
    "print(\"\\nTest Dataset Summary Statistics:\")\n",
    "print(test_df.describe())\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f2c95fc0bb94843",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot distribution of labels in the training dataset\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='label', data=train_df)\n",
    "plt.title('Label Distribution in Training Data')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bc407c4354a5129",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Distribution of review lengths in the training dataset\n",
    "train_df['review_length'] = train_df['content'].apply(len)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['review_length'], bins=50, kde=True)\n",
    "plt.title('Distribution of Review Lengths in Training Data')\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c202341d0fdd53",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Most common words in positive and negative reviews\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the function to fix the IndexError\n",
    "def plot_most_common_words_corrected(df, n=20):\n",
    "    pos_reviews = df[df['label'] == 1]['content']\n",
    "    neg_reviews = df[df['label'] == 0]['content']\n",
    "\n",
    "    vectorizer_pos = CountVectorizer(stop_words='english')\n",
    "    vectorizer_neg = CountVectorizer(stop_words='english')\n",
    "\n",
    "    pos_word_count = vectorizer_pos.fit_transform(pos_reviews)\n",
    "    neg_word_count = vectorizer_neg.fit_transform(neg_reviews)\n",
    "\n",
    "    pos_sum_words = pos_word_count.sum(axis=0)\n",
    "    neg_sum_words = neg_word_count.sum(axis=0)\n",
    "\n",
    "    pos_words_freq = [(word, pos_sum_words[0, idx]) for word, idx in\n",
    "                      zip(vectorizer_pos.get_feature_names_out(), range(pos_sum_words.shape[1]))]\n",
    "    neg_words_freq = [(word, neg_sum_words[0, idx]) for word, idx in\n",
    "                      zip(vectorizer_neg.get_feature_names_out(), range(neg_sum_words.shape[1]))]\n",
    "\n",
    "    pos_words_freq = sorted(pos_words_freq, key=lambda x: x[1], reverse=True)\n",
    "    neg_words_freq = sorted(neg_words_freq, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Plot for positive reviews\n",
    "    words, freq = zip(*pos_words_freq[:n])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(words, freq)\n",
    "    plt.title('Most common words in positive reviews')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot for negative reviews\n",
    "    words, freq = zip(*neg_words_freq[:n])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(words, freq)\n",
    "    plt.title('Most common words in negative reviews')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the corrected function\n",
    "plot_most_common_words_corrected(train_df)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16e5ab3e96884fed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "\n",
    "# Generate a word cloud for positive reviews\n",
    "def generate_word_cloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=800,\n",
    "                          background_color='white',\n",
    "                          stopwords=set(STOPWORDS),\n",
    "                          min_font_size=10).generate(text)\n",
    "\n",
    "    # Plot the WordCloud image                        \n",
    "    plt.figure(figsize=(8, 8), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Concatenate all positive reviews into a single string\n",
    "pos_reviews_text = \" \".join(review for review in train_df[train_df['label'] == 1]['content'])\n",
    "\n",
    "# Concatenate all negative reviews into a single string\n",
    "neg_reviews_text = \" \".join(review for review in train_df[train_df['label'] == 0]['content'])\n",
    "\n",
    "# Generate word cloud for positive reviews\n",
    "generate_word_cloud(pos_reviews_text, \"Word Cloud for Positive Reviews\")\n",
    "\n",
    "# Generate word cloud for negative reviews\n",
    "generate_word_cloud(neg_reviews_text, \"Word Cloud for Negative Reviews\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737b0525d667d911",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_df[\"content_vector\"] = generator.generate_embeddings(text_col=train_df[\"content\"])\n",
    "test_df[\"content_vector\"] = generator.generate_embeddings(text_col=test_df[\"content\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7a72cc6a116549e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_batch_size = 16\n",
    "training_epochs = 3\n",
    "logging_steps = len(train_df) // training_batch_size\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=training_epochs,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=training_batch_size,\n",
    "                                  per_device_eval_batch_size=training_batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  log_level=\"error\",\n",
    "                                  optim=\"adamw_torch\"\n",
    "                                  )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bb1e24d3ad77bb3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tokenize(batch, max_length=512):\n",
    "    return tokenizer(batch['content'], padding=True, truncation=True, max_length=max_length)\n",
    "   \n",
    "process_batch_size = 100\n",
    "max_size = 100 # max length of the tokenized sequence\n",
    "\n",
    "train_ds = train_ds.map(lambda batch: tokenize(batch, max_size), batched=True, batch_size=process_batch_size)\n",
    "test_ds = test_ds.map(lambda batch: tokenize(batch, max_size), batched=True, batch_size=process_batch_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6d53bab06d15ad5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "type(train_ds)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91e0b3be41d90178",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "793a9a859d036d14",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "eval = trainer.evaluate()\n",
    "eval_df = pd.DataFrame({'Epoch':0, 'Validation Loss': eval['eval_loss'], 'Accuracy': eval['eval_accuracy'], 'F1': eval['eval_f1']}, index=[0])\n",
    "\n",
    "eval_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5155e78be1c3b9ef",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nTraining...\")\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f391f63f1b19adb7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ## TODO WIP is broke but ideally I want to extract the embeddings and predictions from the model and add them to the dataset so we can look at them in phoenix\n",
    "# def postprocess(batch):\n",
    "#     inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "#     with torch.no_grad():\n",
    "#         out = model(**inputs)                         # Extract prediction labels\n",
    "#         pred_label = out.logits.argmax(dim=1)           # Extract embedding vectors\n",
    "#         hidden_states = torch.stack(out.hidden_states)  # (layer_#, batch_size, seq_length/or/num_tokens, hidden_size)\n",
    "#         embeddings = hidden_states[-1][:,0,:]           # Select last layer, then CLS token vector\n",
    "#     return {\"text_vector\": embeddings.cpu().numpy(), \"pred_label\": pred_label.cpu().numpy()}\n",
    "# \n",
    "# batch_size = 100\n",
    "# \n",
    "# \n",
    "# train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "# train_ds = train_ds.map(postprocess, batched=True, batch_size=batch_size)\n",
    "# \n",
    "# test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "# test_ds = test_ds.map(postprocess, batched=True, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad5a2470c44652b0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9f8aea708868892e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "\n",
    "schema = px.Schema(\n",
    "    actual_label_column_name=\"label\",\n",
    "    embedding_feature_column_names={\n",
    "        \"text_embedding\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"content_vector\", raw_data_column_name=\"content\"\n",
    "        ),\n",
    "    },\n",
    "    ## not working yet\n",
    "    # prediction_label_column_name=\"pred_label\",\n",
    ")\n",
    "\n",
    "test_ds_px = px.Dataset(dataframe=train_df, schema=schema, name=\"testing\")\n",
    "train_ds_px = px.Dataset(dataframe=test_df, schema=schema, name=\"training\")\n",
    "\n",
    "session = px.launch_app(primary=test_ds_px, reference=train_ds_px)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bae0e1ea37c47f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "px.active_session().view()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "165d3db509f5064",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aad0501f22d42d09",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "334164e0b1f35a59",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
